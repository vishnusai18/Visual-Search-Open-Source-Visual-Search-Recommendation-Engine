{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74a5b7d1-7302-4123-bda6-627bc0ac73ba",
   "metadata": {},
   "source": [
    "### This NoteBook Information\n",
    "- This Notebook contains the code & steps involved in generating images from array & saving them for further usuage in the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de97aac-92a7-4b76-a054-01d43e15f038",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "347e07bd-35e0-4fea-babb-af763b3c7a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist # This Libraray is to fetch fashion dataset from mnist pool\n",
    "import numpy as np # This Library helps in handling arrays\n",
    "from mnist import fashion_mnist # This pool contains train & test dataset of 10 different categories of fashion items\n",
    "from PIL import Image # This Library used to open and save images \n",
    "import os # This Library helps in creating files or folders and organize them locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cbfa14-358f-4289-93be-17ebc34acd04",
   "metadata": {},
   "source": [
    "#### Fixed Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e60eea45-16c2-4a9c-9fd3-dc47a95c51d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGES_PATH = \"./Data/Images_Train/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98235bae-ffe3-459b-9a84-c729fda2cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(TRAIN_IMAGES_PATH,exist_ok=True) # Creating folder to store train images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d762d59-6e81-44ac-8f3b-cf81d35ce22c",
   "metadata": {},
   "source": [
    "#### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e459ea4b-36a3-4172-9d24-1897eaead6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MNIST] Caching data at FASHION_MNIST\n",
      "[MNIST] Found http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz in cache.\n",
      "[MNIST] Found http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz in cache.\n",
      "[MNIST] Found http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz in cache.\n",
      "[MNIST] Found http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz in cache.\n"
     ]
    }
   ],
   "source": [
    "x_train_fashion, y_train_fashion, x_test_fashion, y_test_fashion = fashion_mnist('FASHION_MNIST') # Reading train & test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99283f0c-c347-426a-ac84-6b4bc39028f9",
   "metadata": {},
   "source": [
    "#### Data Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd735e49-fc7f-4145-9243-08f7f9532790",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_label = {0: \"T-shirt-top\",\n",
    "1: \"Trouser\",\n",
    "2: \"Pullover\",\n",
    "3: \"Dress\",\n",
    "4: \"Coat\",\n",
    "5: \"Sandal\",\n",
    "6: \"Shirt\",\n",
    "7: \"Sneaker\",\n",
    "8: \"Bag\",\n",
    "9: \"Ankle boot\",}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c50b0d1-3b81-462c-9ac6-c9af1cc301f8",
   "metadata": {},
   "source": [
    "#### Feature Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b0929-651e-41c5-ae83-d000b7643e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time # shortcut command that tells the time this cells runs\n",
    "count = 1 # counter to create unique image labellling\n",
    "for img_array,output in zip(x_train_fashion,y_train_fashion):    # looping through the list that contains the img values\n",
    "    img = Image.fromarray(img_array.astype(np.uint8),mode=\"L\") # converting to image from array using numpy\n",
    "    img_rgb = img.convert(\"RGB\") # since it is intially grey scale the size is 28x28, since i will be using CLIP model to create embeddings that woks well with RGB with dimension 224x224x3\n",
    "    img_resized = img_rgb.resize((224, 224))\n",
    "    label = output_label[output]  \n",
    "    filename = f\"img_{count}_label_{label}.png\"  # creating the file name of the image so that each one will be distinct\n",
    "    print(filename)\n",
    "    print(count)\n",
    "    img_resized.save(os.path.join(TRAIN_IMAGES_PATH, filename)) # saving the image \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b279a880-a773-4d4b-9de0-9652e4008a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], shape=(60000,), dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_fashion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
